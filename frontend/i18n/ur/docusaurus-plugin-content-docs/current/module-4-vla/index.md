---
sidebar_position: 1
title: "ویژن-لینگویج-ایکشن ماڈلز"
description: "روبوٹکس کے لیے ملٹی موڈل AI ماڈلز کا تعارف"
---

# ویژن-لینگویج-ایکشن ماڈلز (Vision-Language-Action Models)

ماڈیول 4 میں خوش آمدید۔ **ویژن-لینگویج-ایکشن (VLA)** ماڈلز روبوٹکس AI کی جدید ترین ٹیکنالوجی کی نمائندگی کرتے ہیں، جو روبوٹس کو قدرتی زبان کے احکامات اور بصری مناظر سمجھنے کے قابل بناتے ہیں تاکہ مناسب ایکشنز پیدا کی جا سکیں۔

## سیکھنے کے مقاصد (Learning Objectives)

- VLA آرکیٹیکچر اور صلاحیتیں سمجھیں
- روبوٹس کے لیے وائس کمانڈ انٹرفیسز نافذ کریں
- بڑے لینگویج ماڈلز کو روبوٹ کنٹرول سے جوڑیں
- اینڈ ٹو اینڈ قدرتی زبان روبوٹ سسٹمز بنائیں

## VLA ماڈلز کیا ہیں؟

VLA ماڈلز تین موڈیلٹیز کو ملاتے ہیں:

```text
┌─────────────────────────────────────────────────────────────┐
│                    VLA ماڈل آرکیٹیکچر                        │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│   ┌─────────────┐   ┌─────────────┐   ┌─────────────────┐  │
│   │   ویژن     │   │   لینگویج   │   │     ایکشن       │  │
│   │   انکوڈر   │   │   انکوڈر    │   │    ڈیکوڈر       │  │
│   └──────┬──────┘   └──────┬──────┘   └────────┬────────┘  │
│          │                 │                    │           │
│          │    ┌────────────────────────┐       │           │
│          └────►   ملٹی موڈل فیوژن     ◄───────┘           │
│               │      ٹرانسفارمر       │                    │
│               └───────────┬────────────┘                    │
│                           │                                 │
│                    ┌──────▼──────┐                          │
│                    │   روبوٹ     │                          │
│                    │   ایکشنز    │                          │
│                    └─────────────┘                          │
└─────────────────────────────────────────────────────────────┘
```

### تین موڈیلٹیز (The Three Modalities)

| موڈیلٹی | ان پٹ | مقصد |
|----------|-------|---------|
| **ویژن** | کیمرہ امیجز، ڈیپتھ میپس | سین سمجھنا |
| **لینگویج** | ٹیکسٹ کمانڈز، تقریر | ٹاسک کی وضاحت |
| **ایکشن** | روبوٹ ٹریجیکٹریز | موٹر کنٹرول آؤٹ پٹ |

## VLA ماڈلز کیوں اہم ہیں؟

روایتی روبوٹکس ہر ٹاسک کے لیے واضح پروگرامنگ کی ضرورت ہوتی ہے۔ VLA ماڈلز فعال کرتے ہیں:

### 1. قدرتی زبان کنٹرول (Natural Language Control)

```text
انسان: "سرخ کپ اٹھاؤ اور لیپ ٹاپ کے پاس رکھو"
روبوٹ: [سرخ کپ شناخت] → [گرفت کی منصوبہ بندی] → [اٹھانا] →
       [لیپ ٹاپ تلاش] → [رکھنے کی منصوبہ بندی] → [کپ رکھنا]
```

### 2. زیرو شاٹ جنرلائزیشن (Zero-Shot Generalization)

روبوٹس ایسے ٹاسکس انجام دے سکتے ہیں جن کے لیے انہیں واضح طور پر تربیت نہیں دی گئی:

- **ٹرینڈ**: "سیب اٹھاؤ"
- **جنرلائزڈ**: "سنترہ اٹھاؤ" (ٹریننگ کے دوران کبھی نہیں دیکھا)

### 3. سیمینٹک سمجھ (Semantic Understanding)

سیاق و سباق اور تعلقات کو سمجھنا:

```text
"کانٹا پلیٹ کے بائیں رکھو"
"روبوٹ بازو شخص سے دور کرو"
"بلاکس کو بڑے سے چھوٹے ترتیب دو"
```

## اہم VLA ماڈل آرکیٹیکچرز

### RT-2 (روبوٹکس ٹرانسفارمر 2)

گوگل کا RT-2 ویژن-لینگویج ماڈل بیک بون استعمال کرتا ہے:

```text
┌─────────────────────────────────────────────────────────────┐
│                          RT-2                                │
├─────────────────────────────────────────────────────────────┤
│  ان پٹ: امیج + "کین اٹھاؤ"                                  │
│                                                              │
│  ┌─────────────────────────────────────────────────────────┐│
│  │         PaLI-X / PaLM-E (ویژن-لینگویج ماڈل)            ││
│  └─────────────────────────────────────────────────────────┘│
│                           │                                  │
│  آؤٹ پٹ: ایکشن ٹوکنز → [x: 0.3, y: -0.1, z: 0.5, ...]     │
└─────────────────────────────────────────────────────────────┘
```

### OpenVLA

ریسرچ کے لیے اوپن سورس VLA ماڈل:

- **7B پیرامیٹر ماڈل** Llama 2 سے فائن ٹیون کیا گیا
- **Open X-Embodiment** ڈیٹاسیٹ پر ٹرینڈ
- **متعدد روبوٹ پلیٹ فارمز** سپورٹ کرتا ہے

### PaLM-E

گوگل کا ایمبوڈیڈ ملٹی موڈل لینگویج ماڈل:

- **562B پیرامیٹرز** PaLM اور ViT کو ملا کر
- **فزیکل ورلڈ** کی سمجھ میں گراؤنڈڈ
- **روبوٹ ایکشنز کے بارے میں استدلال** کر سکتا ہے

## VLA پائپ لائن کا جائزہ

```text
┌─────────────────────────────────────────────────────────────┐
│                    VLA روبوٹ سسٹم                            │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌─────────────┐      ┌─────────────┐      ┌─────────────┐ │
│  │   تقریر    │      │   کیمرہ     │      │   روبوٹ     │ │
│  │   ان پٹ    │      │   فیڈ       │      │   اسٹیٹ     │ │
│  └──────┬──────┘      └──────┬──────┘      └──────┬──────┘ │
│         │                    │                    │        │
│         ▼                    ▼                    ▼        │
│  ┌─────────────┐      ┌─────────────┐      ┌─────────────┐ │
│  │   تقریر    │      │   ویژن     │      │   اسٹیٹ     │ │
│  │   ٹو ٹیکسٹ │      │   انکوڈر   │      │   انکوڈر    │ │
│  │  (Whisper) │      │   (ViT)    │      │             │ │
│  └──────┬──────┘      └──────┬──────┘      └──────┬──────┘ │
│         │                    │                    │        │
│         └────────────────────┼────────────────────┘        │
│                              ▼                             │
│                   ┌─────────────────────┐                  │
│                   │     VLA ماڈل       │                  │
│                   │  (ایکشن ڈیکوڈر)    │                  │
│                   └──────────┬──────────┘                  │
│                              │                             │
│                              ▼                             │
│                   ┌─────────────────────┐                  │
│                   │   ایکشن ایگزیکیوٹر │                  │
│                   │   (روبوٹ کنٹرول)   │                  │
│                   └─────────────────────┘                  │
└─────────────────────────────────────────────────────────────┘
```

## ہارڈویئر تقاضے

### VLA ماڈلز کی ٹریننگ

| جز | کم از کم | تجویز کردہ |
|-----------|---------|-------------|
| GPU | 8× A100 40GB | 8× H100 80GB |
| RAM | 512 GB | 1 TB |
| سٹوریج | 10 TB NVMe | 50 TB NVMe |

### انفرنس/ڈیپلائمنٹ

| پلیٹ فارم | ماڈل سائز | کارکردگی |
|----------|------------|-------------|
| Jetson AGX Orin | 7B (کوانٹائزڈ) | ~5 Hz |
| RTX 4090 | 7B | ~15 Hz |
| A100 | 7B | ~30 Hz |

## ROS2 کے ساتھ انٹیگریشن

VLA ماڈلز روبوٹ کنٹرول کے لیے ROS2 سے انٹیگریٹ ہوتے ہیں:

```python title="vla_controller.py"
#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import Twist
from std_msgs.msg import String

class VLAController(Node):
    """VLA بیسڈ روبوٹ کنٹرول کے لیے ROS2 نوڈ۔"""

    def __init__(self):
        super().__init__('vla_controller')

        # کیمرے کو سبسکرائب کریں
        self.image_sub = self.create_subscription(
            Image, '/camera/image_raw', self.image_callback, 10
        )

        # وائس کمانڈز کو سبسکرائب کریں
        self.command_sub = self.create_subscription(
            String, '/voice_command', self.command_callback, 10
        )

        # ویلوسٹی کمانڈز پبلش کریں
        self.cmd_pub = self.create_publisher(Twist, '/cmd_vel', 10)

        # اسٹیٹ
        self.current_image = None
        self.current_command = None

        # VLA ماڈل (الگ سے لوڈ کیا جائے گا)
        self.vla_model = None  # اپنا VLA ماڈل یہاں شروع کریں

        self.get_logger().info('VLA کنٹرولر شروع ہو گیا')

    def image_callback(self, msg):
        self.current_image = msg

    def command_callback(self, msg):
        self.current_command = msg.data
        self.execute_vla()

    def execute_vla(self):
        """VLA انفرنس چلائیں اور ایکشن انجام دیں۔"""
        if self.current_image is None or self.current_command is None:
            return

        # VLA ماڈل چلائیں
        # action = self.vla_model.predict(self.current_image, self.current_command)

        # روبوٹ کمانڈ میں تبدیل کریں
        cmd = Twist()
        # cmd.linear.x = action['linear_x']
        # cmd.angular.z = action['angular_z']
        self.cmd_pub.publish(cmd)

def main():
    rclpy.init()
    node = VLAController()
    rclpy.spin(node)
    rclpy.shutdown()
```

## ماڈیول کا ڈھانچہ

یہ ماڈیول شامل ہے:

1. **[وائس کمانڈز](./voice-commands)** - روبوٹ کنٹرول کے لیے تقریر کی شناخت
2. **[LLM انٹیگریشن](./llm-integration)** - لینگویج ماڈلز کو روبوٹس سے جوڑنا

## ایپلیکیشنز

VLA ماڈلز نئی روبوٹکس ایپلیکیشنز فعال کرتے ہیں:

| ایپلیکیشن | تفصیل |
|-------------|-------------|
| **گھریلو مدد** | "لونگ روم صاف کرو" → خودکار صفائی |
| **ویئر ہاؤس** | "شیلف B3 سے آئٹم #12345 لاؤ" |
| **مینوفیکچرنگ** | "اجزاء ترتیب سے جوڑو" |
| **صحت** | "سرجیکل آلہ دو" |
| **زراعت** | "پکے ٹماٹر کاٹو" |

## چیلنجز اور حدود

### موجودہ حدود

1. **انفرنس کی رفتار**: بڑے ماڈلز ریئل ٹائم کنٹرول کے لیے سست ہیں
2. **سیفٹی**: زبان کی سمجھ کی غلطیاں غیر محفوظ ایکشنز کا سبب بن سکتی ہیں
3. **جنرلائزیشن**: واقعی نئے منظرناموں سے ابھی بھی جدوجہد
4. **ڈیٹا کی ضروریات**: بڑے پیمانے پر روبوٹ تعامل ڈیٹاسیٹس کی ضرورت

### فعال ریسرچ کے شعبے

- **موثر آرکیٹیکچرز** ریئل ٹائم انفرنس کے لیے
- **سیفٹی کنسٹرینٹس** ایکشن جنریشن میں
- **فیو شاٹ لرننگ** نئے ٹاسکس کے لیے
- **سم ٹو ریئل ٹرانسفر** VLA ماڈلز کے لیے

## خلاصہ (Summary)

- **VLA ماڈلز** ویژن، لینگویج، اور ایکشن کو ملاتے ہیں
- **قدرتی زبان** بدیہی روبوٹ کنٹرول فعال کرتی ہے
- **زیرو شاٹ جنرلائزیشن** نئے ٹاسکس کو سنبھالنے کی اجازت دیتی ہے
- **ROS2 سے انٹیگریشن** حقیقی روبوٹس پر ڈیپلائمنٹ فعال کرتا ہے
- **موجودہ حدود** میں رفتار اور سیفٹی کے خدشات شامل ہیں

**اگلا**: [وائس کمانڈز](./voice-commands) - روبوٹس کے لیے تقریر انٹرفیسز بنائیں۔
